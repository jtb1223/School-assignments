{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw 05/06/21.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrq1gjCrcRZjr4cP+ptZVe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtb1223/School-assignments/blob/main/hw_05_06_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics\n",
        "\n",
        "Explain in words what accuracy, precision, and recall are.  Describe a situation when you would prefer one to another and where the shortcomings to each lays. \n",
        "\n",
        "What is a confusion matrix?\n",
        "\n",
        "Write the python code for accuracy, precision, recall, and F1\n",
        "\n",
        "Give your own example of a type 1 and type 2 error\n",
        "\n",
        "Why do we use train.test,split() function from Python when analyzing data? \n",
        "\n",
        "What is the point of splitting data?\n",
        "\n",
        "What is the bias vs. variance tradeoff?"
      ],
      "metadata": {
        "id": "TcFIxvzHoOhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####"
      ],
      "metadata": {
        "id": "ZPz--barygwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy: Accuracy tells us how often we can expect our machine learning model will correctly predict an outcome out of the total number of times it made predictions.\n",
        "\n",
        "Precision: Precision is used in conjunction with the recall to trade-off false positives and false negatives. It measures the proportion of positively predicted labels that are actually correct.\n",
        "\n",
        "Recall: Recall score represents the modelâ€™s ability to correctly predict the positives out of actual positives. It measures how good our machine learning model is at identifying all actual positives out of all positives that exist within a dataset. \n"
      ],
      "metadata": {
        "id": "g4TCRiHfpFW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix: This is used to describe the performance of a classification model on a set of data. "
      ],
      "metadata": {
        "id": "ARdK-TC7o3S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Accuracy example\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = [0, 2, 1, 3]\n",
        "y_true = [0, 1, 2, 3]\n",
        "accuracy_score(y_true, y_pred)\n",
        "accuracy_score(y_true, y_pred, normalize=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvVIKda5u71L",
        "outputId": "8ed1dd45-d50a-4dc8-f057-7f32d6264fd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Precision example\n",
        "from sklearn.metrics import precision_score\n",
        "y_true = [0, 1, 2, 0, 1, 2]\n",
        "y_pred = [0, 2, 1, 0, 0, 1]\n",
        "precision_score(y_true, y_pred, average='macro')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj_VUDzlvOQz",
        "outputId": "5d20babb-7b2d-47ae-fe3d-808c01a05194"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2222222222222222"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Recall example\n",
        "from sklearn.metrics import recall_score\n",
        "y_true = [0, 1, 2, 0, 1, 2]\n",
        "y_pred = [0, 2, 1, 0, 0, 1]\n",
        "recall_score(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ons9FpdgvOYq",
        "outputId": "62d5327f-8137-4c0e-999b-6548e4ff4ef0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## F1 example\n",
        "from sklearn.metrics import f1_score\n",
        "y_true = [0, 1, 2, 0, 1, 2]\n",
        "y_pred = [0, 2, 1, 0, 0, 1]\n",
        "f1_score(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dl4KTEkvTca",
        "outputId": "3a2e3fa2-33d1-43b8-8099-ff35ec425723"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of a type 1 error is a false positive or when u get a result saying you have a cold but you actually dont. \n",
        "\n",
        "An example of a type 2 error is a false negative or when the result says u dont have a cold but you actually do.\n"
      ],
      "metadata": {
        "id": "tOby9IV0wonc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the train_test_split() function to split a dataset into train and test sets to show how well the machine learning model performs.\n",
        "\n",
        "We split the data in order to make sure the prediction performance is unbiased.\n",
        "\n",
        "The bias vs. variance tradeoff: the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters."
      ],
      "metadata": {
        "id": "2WNak2QGxTsv"
      }
    }
  ]
}